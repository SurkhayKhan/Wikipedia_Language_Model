# -*- coding: utf-8 -*-
"""without_back_off

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11hG8PwSEEdeklWNJXoPnc9d6ym9kmQwV
"""

import re
from collections import defaultdict, Counter
from math import log2

def preprocess(text):
    text = text.lower()
    words = re.findall(r'\b\w+\b', text)
    return words

def ngrams(words, n=2):
    return list(zip(*[words[i:] for i in range(n)]))

def train_ngram_model(corpus):
    model = defaultdict(Counter)
    for word1, word2 in ngrams(corpus):
        model[word1][word2] += 1
    return model

def perplexity_without_backoff(test_data, model):
    total_log_prob = 0
    test_bigrams = ngrams(test_data)
    for word1, word2 in test_bigrams:
        prob = get_probability_without_backoff(model, word1, word2)
        if prob > 0:
            total_log_prob += -1 * log2(prob)
    return 2 ** (total_log_prob / len(test_bigrams))

def get_probability_without_backoff(model, word1, word2):
    word1_count = sum(model[word1].values())
    word2_given_word1_count = model[word1][word2]
    if word1_count == 0:
        return 0
    prob = word2_given_word1_count / word1_count
    return prob

# Load and preprocess datasets
datasets = {
    'wikitext': {
        'train': 'wiki.train.raw',
        'valid': 'wiki.valid.raw',
        'test': 'wiki.test.raw',
    },
    'ptb': {
        'train': 'ptb.train.txt',
        'valid': 'ptb.valid.txt',
        'test': 'ptb.test.txt',
    }
}

preprocessed_data = {}
for dataset_name, dataset_files in datasets.items():
    preprocessed_data[dataset_name] = {}
    for data_type, file_path in dataset_files.items():
        if file_path:
            with open(file_path, 'r') as f:
                text = f.read()
            preprocessed_data[dataset_name][data_type] = preprocess(text)

models = {}
for dataset_name, preprocessed_texts in preprocessed_data.items():
    # Train 2-gram model on the training dataset
    models[dataset_name] = train_ngram_model(preprocessed_texts['train'])

for dataset_name, model in models.items():
    print(f'{dataset_name.capitalize()} dataset results (without back-off):')
    for data_type, preprocessed_text in preprocessed_data[dataset_name].items():
        perplexity_value = perplexity_without_backoff(preprocessed_text, model)
        print(f'  {data_type.capitalize()} Perplexity:', perplexity_value)
    print()